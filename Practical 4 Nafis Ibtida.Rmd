---
title: "Practical 4"
author: "Nafis Ibtida Chowdhury B00935437"
date: "2024-06-16"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

There are 3-4 packages you will need to install for today's practical: `install.packages(c("xgboost", "eegkit", "forecast", "tseries", "caret"))` apart from that everything else should already be available on your system. 

If you are using a newer Mac you may have to also install [quartz](https://www.xquartz.org/) to have everything work (do this if you see errors about `X11` during install/execution).

I will endeavour to use explicit imports to make it clear where functions are coming from (functions without `library_name::` are part of base R or a function we've defined in this notebook).

```{r libraries, echo=FALSE}
# Using the same library we used earlier in the course for tabular data because we know it works!
library(xgboost)

# EEG manipulation library in R (although very limited compared to signal processing libraries available in other languages, matlab might actually still be a leader in this specific area)
library(eegkit)

# some time series functions (that we only skim the depths of)
library(forecast)
library(tseries)
library(caret)

# just tidyverse libraries that should already be installed
library(dplyr)
library(reshape2)
library(purrr)
library(ggplot2)
```

```{r}

install.packages("fastmap")

```

## EEG Eye Detection Data

One of the most common types of medical sensor data (and one that we talked about during the lecture) are Electroencephalograms (EEGs).  
These measure mesoscale electrical signals (measured in microvolts) within the brain, which are indicative of a region of neuronal activity.
Typically, EEGs involve an array of sensors (aka channels) placed on the scalp with a high degree of covariance between sensors.

As EEG data can be very large and unwieldy, we are going to use a relatively small/simple dataset today from [this paper](http://ehrai.com/su/pdf/aihls2013.pdf).

This dataset is a 117 second continuous EEG measurement collected from a single person with a device called a "Emotiv EEG Neuroheadset".
In combination with the EEG data collection, a camera was used to record whether person being recorded had their eyes open or closed. 
This was eye status was then manually annotated onto the EEG data with `1` indicated the eyes being closed and `0` the eyes being open.
Measures microvoltages are listed in chronological order with the first measured value at the top of the dataframe.

Let's parse the data directly from the `h2o` library's (which we aren't actually using directly) test data S3 bucket:

```{r parse_data}
eeg_url <- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate_splits.csv"
eeg_data <- read.csv(eeg_url)

# add timestamp
Fs <- 117 / nrow(eeg_data)
eeg_data <- transform(eeg_data, ds = seq(0, 116.99999, by = Fs), eyeDetection = as.factor(eyeDetection))
print(table(eeg_data$eyeDetection))

# split dataset into train, validate, test
eeg_train <- subset(eeg_data, split == 'train', select = -split)
print(table(eeg_train$eyeDetection))

eeg_validate <- subset(eeg_data, split == 'valid', select = -split)
eeg_test <- subset(eeg_data, split == 'test', select = -split)
```

**0** Knowing the `eeg_data` contains 117 seconds of data, inspect the `eeg_data` dataframe and the code above to and determine how many samples per second were taken?

```{r}
# Inspect the number of rows in the dataframe
total_samples <- nrow(eeg_data)

# Given duration in seconds
duration_seconds <- 117

# Calculate samples per second (sampling rate)
sampling_rate <- total_samples / duration_seconds

# Print the sampling rate
cat("Sampling Rate:", sampling_rate, "samples per second\n")
```

**1** How many EEG electrodes/sensors were used?

First, Inspects the structure of the dataframe to understand its composition.
Then, Counts the total number of columns in the dataframe.
Assumes that eye_opening is the only non-sensor column and subtracts it from the total column count to get the number of EEG sensors.
Prints the calculated number of EEG sensors.

```{r}
# Check the structure of the eeg_data dataframe
str(eeg_data)

# Get the number of columns in the dataframe
num_columns <- ncol(eeg_data)

# Assuming 'eye_opening' is the target variable and the rest are EEG sensors
# Subtract 1 to account for the target variable column
num_eeg_sensors <- num_columns - 1

# Print the number of EEG sensors
cat("Number of EEG electrodes/sensors used:", num_eeg_sensors, "\n")
```
Number of EEG electrodes/sensors used: 16

### Exploratory Data Analysis

Now that we have the dataset and some basic parameters let's begin with the ever important/relevant exploratory data analysis.

First we should check there is no missing data!
```{r check_na}
sum(is.na(eeg_data))
```

Great, now we can start generating some plots to look at this data within the time-domain.

First we use `reshape2::melt()` to transform the `eeg_data` dataset from a wide format to a long format expected by `ggplot2`.

Specifically, this converts from "wide" where each electrode has its own column, to a "long" format, where each observation has its own row. 
This format is often more convenient for data analysis and visualization, especially when dealing with repeated measurements or time-series data.

We then use `ggplot2` to create a line plot of electrode intensities per sampling time, with the lines coloured by electrode, and the eye status annotated using dark grey blocks.

```{r plot_data}
melt <- reshape2::melt(eeg_data %>% dplyr::select(-split), id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")


ggplot2::ggplot(melt, ggplot2::aes(x=ds, y=microvolts, color=Electrode)) + 
  ggplot2::geom_line() + 
  ggplot2::ylim(3500,5000) + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(melt, eyeDetection==1), alpha=0.005)
```

**2** Do you see any obvious patterns between eyes being open (dark grey blocks in the plot) and the EEG intensities?

Considering the dark grey blocks indicating periods when the eyes are open, there doesn't appear to be a consistent or obvious pattern between eye openness and EEG intensities across all electrodes. However, during longer periods of eye openness, EEG signal fluctuations seem to subside and become more consistent. This may be because when the eyes are open, the brain is actively processing visual information from the environment, which stimulates various brain regions, including the visual cortex. This activation can influence other brain areas, leading to more synchronized neural activity and resulting in less noisy EEG signals during open-eye periods.


**3** Similarly, based on the distribution of eye open/close state over time to anticipate any temporal correlation between these states?

```{r}
# Calculate the proportion of time spent in each state over different time intervals
time_intervals <- seq(0, max(eeg_data$ds), by = 1)  # 1 second intervals
state_distribution <- eeg_data %>%
  dplyr::mutate(time_interval = cut(ds, breaks = time_intervals)) %>%
  dplyr::group_by(time_interval) %>%
  dplyr::summarize(
    proportion_closed = mean(eyeDetection == 1),
    proportion_open = mean(eyeDetection == 0)
  )

# Plot the proportion of time spent in each state over time intervals
ggplot(state_distribution, aes(x = as.numeric(time_interval))) +
  geom_line(aes(y = proportion_closed, color = "Closed")) +
  geom_line(aes(y = proportion_open, color = "Open")) +
  labs(x = "Time (seconds)", y = "Proportion", title = "Proportion of Eye States Over Time") +
  scale_color_manual(values = c("Closed" = "green", "Open" = "blue")) +
  theme_minimal()
## Warning: Removed 1 row containing missing values or values outside the scale range
## (`geom_line()`).
## Removed 1 row containing missing values or values outside the scale range
## (`geom_line()`).
```
The plot visualizes EEG electrode intensities over time, with each line representing a different electrode. Vertical green blocks indicate periods when the eyes are closed, while blue blocks indicate periods when the eyes are open. It appears that EEG signals decrease when the eyes are open, supporting the notion that the brain is actively processing visual information from the environment during these times. The changes in microvolt levels during periods of eye opening suggest a measurable impact of eye state on the brainâ€™s electrical activity.

Let's see if we can directly look at the distribution of EEG intensities and see how they related to eye status.


As there are a few extreme outliers in voltage we will use the `dplyr::filter` function to remove values outwith of 3750 to 50003. The function uses the `%in%` operator to check if each value of microvolts is within that range. The function also uses the `dplyr::mutate()` to change the type of the variable eyeDetection from numeric to a factor (R's categorical variable type).

```{r compare_distrib}
melt_train <- reshape2::melt(eeg_train, id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")

# filter huge outliers in voltage
filt_melt_train <- dplyr::filter(melt_train, microvolts %in% (3750:5000)) %>% dplyr::mutate(eyeDetection=as.factor(eyeDetection))

ggplot2::ggplot(filt_melt_train, ggplot2::aes(y=Electrode, x=microvolts, fill=eyeDetection)) + ggplot2::geom_boxplot()
```



Plots are great but sometimes so it is also useful to directly look at the summary statistics and how they related to eye status.
We will do this by grouping the data based on eye status and electrode before calculating the statistics using the convenient `dplyr::summarise` function.

```{r compare_summary_stats}
filt_melt_train %>% dplyr::group_by(eyeDetection, Electrode) %>% 
    dplyr::summarise(mean = mean(microvolts), median=median(microvolts), sd=sd(microvolts)) %>% 
    dplyr::arrange(Electrode)
```




**4** Based on these analyses are any electrodes consistently more intense or varied when eyes are open?

To understand the impact of eye state on EEG electrodes, we analyzed the mean, median, and standard deviation of microvolt levels for each electrode. The mean values show minor differences between eyes open and closed. However, the standard deviation indicates that electrodes F7, FC5, and O1 exhibit more variability when the eyes are open, while electrodes FC6, F4, F8, and AF4 show consistent variability regardless of eye state. Despite these observations, the differences are relatively small, suggesting that eye state alone does not have a significant impact on EEG electrodes based on this analysis.

#### Time-Related Trends

As it looks like there may be a temporal pattern in the data we should investigate how it changes over time.  

First we will do a statistical test for stationarity:

```{r convert_to_tseries}
apply(eeg_train, 2, tseries::adf.test)
```


**5** What is stationarity?

Stationarity refers to a statistical property of a time series whereby its statistical characteristics, such as mean, variance, and autocorrelation, remain constant over time. In other words, a stationary time series does not exhibit trends, seasonality, or other patterns that change over time. This property is crucial in time series analysis and forecasting because many statistical models and methods assume stationarity, allowing for more reliable predictions and inferences about the underlying data-generating process. Stationarity simplifies the modeling process by ensuring that the behavior of the time series is consistent throughout its duration.

**6** Why are we interested in stationarity? What do the results of these tests tell us? (ignoring the lack of multiple comparison correction...)

We are interested in stationarity because many statistical models and forecasting methods assume that the time series data they analyze are stationary. Stationarity ensures that the time series' properties, such as mean and variance, are constant over time, making the model's predictions more reliable and interpretable. The results of stationarity tests, like the Augmented Dickey-Fuller (ADF) test, inform us whether a time series is stationary or if it needs to be transformed to achieve stationarity. This helps in selecting appropriate modeling techniques and improving the accuracy of forecasts. If the tests indicate non-stationarity, it suggests that the data exhibits trends, seasonality, or other patterns that need to be addressed before proceeding with further analysis.

The results show that electrodes AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4, as well as the eyeDetection and ds columns, all have p-values less than 0.01. This suggests that these variables are stationary, ensuring the stability and reliability of the modeling.

Then we may want to visually explore patterns of autocorrelation (previous values predict future ones) and cross-correlation (correlation across channels over time) using `forecast::ggAcf` function.

The ACF plot displays the cross- and auto-correlation values for different lags (i.e., time delayed versions of each electrode's voltage timeseries) in the dataset. 
It helps identify any significant correlations between channels and observations at different time points. 
Positive autocorrelation indicates that the increase in voltage observed in a given time-interval leads to a proportionate increase in the lagged time interval as well.
Negative autocorrelation indicates the opposite!


```{r correlation}
forecast::ggAcf(eeg_train %>% dplyr::select(-ds))
```





**7** Do any fields show signs of strong autocorrelation (diagonal plots)? Do any pairs of fields show signs of cross-correlation? Provide examples.

Autocorrelation measures the correlation between a variable and its past values at different lags, while cross-correlation assesses the similarity between two distinct signals as a function of time lag. In the diagonal plots, we observe autocorrelation for individual electrodes, with significant peaks at lag 0 indicating strong self-correlation. Notably, electrodes F5, O1, and FC6 show signs of autocorrelation. The off-diagonal plots depict cross-correlation between electrode pairs, such as AF3 and F7. However, no significant cross-correlation is evident between any electrode pairs.


#### Frequency-Space 

We can also explore the data in frequency space by using a Fast Fourier Transform.  
After the FFT we can summarise the distributions of frequencies by their density across the power spectrum.
This will let us see if there any obvious patterns related to eye status in the overall frequency distributions.

```{r fft_open}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 0) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Open")
```

```{r fft_closed}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 1) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Closed")
```




**8** Do you see any differences between the power spectral densities for the two eye states? If so, describe them.

The two plots display the power spectral density (PSD) across different EEG channels for 'Eye Open' and 'Eye Closed' conditions. Patterns related to eye status are evident as distinctive peaks or variations in power density. The PSD plot for eyes closed shows a more varied and intense power density, while for eyes open, the power density is more consistent over time. In summary, these plots reveal differences in EEG power distribution based on eye status, offering insights into brain dynamics during different states.

#### Independent Component Analysis

We may also wish to explore whether there are multiple sources of neuronal activity being picked up by the sensors.  
This can be achieved using a process known as independent component analysis (ICA) which decorrelates the channels and identifies the primary sources of signal within the decorrelated matrix.

```{r ica, warning=FALSE}
ica <- eegkit::eegica(eeg_train %>% dplyr::select(-eyeDetection, -ds), nc=3, method='fast', type='time')
mix <- dplyr::as_tibble(ica$M)
mix$eyeDetection <- eeg_train$eyeDetection
mix$ds <- eeg_train$ds

mix_melt <- reshape2::melt(mix, id.vars=c("eyeDetection", "ds"), variable.name = "Independent Component", value.name = "M")


ggplot2::ggplot(mix_melt, ggplot2::aes(x=ds, y=M, color=`Independent Component`)) + 
  ggplot2::geom_line() + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(mix_melt, eyeDetection==1), alpha=0.005) +
  ggplot2::scale_y_log10()
```



**9** Does this suggest eye opening relates to an independent component of activity across the electrodes?

The output plot suggests that eye opening affects an independent component (IC) of neuronal activity across the electrodes. Vertical grey lines indicate eye opening, during which noticeable fluctuations in IC activities occur. Specifically, V1 shows patterns related to eye blink onset, while V3 captures the eye blink offset following visual letter presentations. These ICs display temporally distinct activity patterns.

### Eye Opening Prediction

Now that we've explored the data let's use a simple model to see how well we can predict eye status from the EEGs:

```{r xgboost}
# Convert the training and validation datasets to matrices
eeg_train_matrix <- as.matrix(dplyr::select(eeg_train, -eyeDetection, -ds))
eeg_train_labels <- as.numeric(eeg_train$eyeDetection) -1

eeg_validate_matrix <- as.matrix(dplyr::select(eeg_validate, -eyeDetection, -ds))
eeg_validate_labels <- as.numeric(eeg_validate$eyeDetection) -1

# Build the xgboost model
model <- xgboost(data = eeg_train_matrix, 
                 label = eeg_train_labels,
                 nrounds = 100,
                 max_depth = 4,
                 eta = 0.1,
                 objective = "binary:logistic")

print(model)
```



**10** Using the `caret` library (or any other library/model type you want such as a naive Bayes) fit another model to predict eye opening.

```{r model2}
# Load necessary libraries
library(e1071)
library(dplyr)
library(caret)

# Prepare the data
eeg_train_nb <- eeg_train %>% dplyr::select(-ds)
eeg_validate_nb <- eeg_validate %>% dplyr::select(-ds)

# Fit a Naive Bayes model
nb_model <- naiveBayes(eyeDetection ~ ., data = eeg_train_nb)

# Make predictions on the validation set
nb_preds <- predict(nb_model, eeg_validate_nb)

# Calculate accuracy
nb_accuracy <- mean(nb_preds == eeg_validate$eyeDetection)

# Print accuracy
print(paste("Naive Bayes Accuracy:", round(nb_accuracy, 2)))

# Confusion matrix and other metrics
nb_confusion_matrix <- confusionMatrix(nb_preds, eeg_validate$eyeDetection)
print(nb_confusion_matrix)
```
The Naive Bayes model achieved an overall accuracy of 47.86%, correctly predicting the eye status about half the time. Its sensitivity (true positive rate) for eye opening is low at 20%, indicating poor performance in identifying when eyes are open. However, its specificity (true negative rate) is higher at 81.34%, meaning it is better at identifying when eyes are closed. The balanced accuracy is 50.67%, slightly better than random guessing. Overall, the model struggles to predict eye opening effectively from the EEG data.

**11** Using the best performing of the two models (on the validation dataset) calculate and report the test performance (filling in the code below):

```{r}
# Convert test dataset to matrix
eeg_test_matrix <- as.matrix(dplyr::select(eeg_test, -eyeDetection, -ds))
eeg_test_labels <- as.numeric(eeg_test$eyeDetection) - 1

# Make predictions on the test set
xgb_preds <- predict(model, newdata = eeg_test_matrix)

# Convert probabilities to binary predictions (assuming threshold 0.5)
xgb_preds_binary <- ifelse(xgb_preds > 0.5, 1, 0)
```

```{r}
# Convert predicted labels to factor with appropriate levels
xgb_preds_factor <- factor(xgb_preds_binary, levels = levels(factor(eeg_test_labels)))

# Convert actual labels to factor with appropriate levels
eeg_test_labels_factor <- factor(eeg_test_labels, levels = levels(factor(xgb_preds_binary)))

# Calculate accuracy
xgb_accuracy <- mean(xgb_preds_factor == eeg_test_labels_factor)

# Print accuracy
print(paste("XGBoost Accuracy on Test Set:", round(xgb_accuracy, 2)))

# Confusion matrix and other metrics
xgb_confusion_matrix <- confusionMatrix(xgb_preds_factor, eeg_test_labels_factor)
print(xgb_confusion_matrix)
```
```{r test}
# Prepare the test data (assuming it's already prepared similar to validation data)
eeg_test_nb <- eeg_test %>% dplyr::select(-ds)

# Make predictions on the test set
nb_preds_test <- predict(nb_model, eeg_test_nb)

# Calculate accuracy
nb_accuracy_test <- mean(nb_preds_test == eeg_test$eyeDetection)

# Print accuracy
print(paste("Naive Bayes Accuracy on Test Set:", round(nb_accuracy_test, 2)))

# Confusion matrix and other metrics
nb_confusion_matrix_test <- confusionMatrix(nb_preds_test, eeg_test$eyeDetection)
print(nb_confusion_matrix_test)
```
We can see that XGBoost performs better than Naive Bayes. The accuracy from XGBoost is 84.35%. whereas that from Naive Bayes is 48.8%.


**12** Describe 2 possible alternative modeling approaches for prediction of eye opening from EEGs we discussed in the lecture but haven't explored in this notebook.

1.Support Vector Machines (SVM) are powerful models used for classification, finding optimal hyperplanes in high-dimensional spaces such as EEG data. They excel in separating classes with a margin and offer robustness against overfitting through various kernel functions (linear, polynomial, RBF).

2.Random Forest, on the other hand, is an ensemble method combining multiple decision trees to enhance classification accuracy. It efficiently handles large datasets and features, providing insights into feature importance, crucial for identifying key EEG predictors.

**13** What are 2 R libraries you could use to implement these approaches? (note: you don't actually have to implement them though!)

In R, the â€˜e1071â€™ package facilitates Support Vector Machines (SVM), offering robust implementations of various machine learning algorithms including SVM through its svm function. It supports kernel functions like linear, polynomial, and radial basis function (RBF), and includes utilities for model tuning, prediction, and evaluation.

For Random Forest modeling in R, the â€˜randomForestâ€™ package is widely utilized. It implements the randomForest function for both classification and regression tasks, enabling parameter tuning such as the number of trees (ntree) and variables tried at each split (mtry). It also provides tools for assessing variable importance and evaluating model performance.

## Optional

**14** (Optional) As this is the last practical of the course - let me know how you would change future offerings of this course. This will not impact your marks!

- What worked and didnâ€™t work for you (e.g., in terms of the practicals, tutorials, and lectures)?

- Was learning how to run the practicals on your own machines instead of a clean server that will disappear after the course worth the technical challenges?
 
- What would you add or remove from the course? 

- What was the main thing you will take away from this course?